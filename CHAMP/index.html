<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

    <title>CHAMP</title>

    <style>
          /* Set your aspect ratio */
      .video-container {
      position: relative;
      overflow: hidden;
      height: 0;
      padding-bottom: 56.25%; /* creates a 16:9 aspect ratio */
      text-align: center;
      width: 800px;
      max-width: 100%;
      margin: 0 auto;
      }

      code { 
        background-color: #eee; 
        padding-left: 4px;
        padding-right: 4px;
        padding-top: 2px;
        padding-bottom: 2px;
      }

      .video-container iframe{
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      max-width: 100%;
      }

      /* And set the max-width of the parent element */
      .video-wrap {
      width: 100%;
      max-width: 800px;
      text-align: center;
      }
    </style>
  </head>
  <body>
    <h2 style="text-align: center; margin-bottom: 5px; margin-top: 30px;">CHAMP: A Competition-level Dataset for Fine-Grained<br>Analyses of LLMs' Mathematical Reasoning Capabilities</h2>
    <h5 style="text-align: center; margin-bottom: 5px; margin-top: 20px;">
      <a target="_blank" rel="noopener noreferrer" href="https://yujunmao1.github.io/">Yujun Mao</a><sup>1</sup>,
      <a target="_blank" rel="noopener noreferrer" href="https://people.csail.mit.edu/yoonkim/">Yoon Kim</a><sup>2</sup>,
      <a target="_blank" rel="noopener noreferrer" href="https://yilunzhou.github.io/">Yilun Zhou</a><sup>2</sup>
    </h5>
    <h6 style="text-align: center; margin-bottom: 5px; margin-top: 10px;">
      <sup>1 </sup>Independent Researcher, <sup>2 </sup>MIT CSAIL
    </h6>
    <h6 style="text-align: center; margin-bottom: 5px; margin-top: 10px;">
      [<a target="_blank" href="https://mathai2023.github.io/papers/14.pdf">Paper</a>] &nbsp;&nbsp;
      [<a target="_blank" href="/CHAMP/explorer.html">Dataset Explorer</a>] &nbsp;&nbsp;
      [<a target="_blank" href="/CHAMP/quickstart.html">Quickstart Guide</a>] &nbsp;&nbsp;
      [<a target="_blank" href="https://github.com/YilunZhou/champ-dataset">GitHub Repo</a>] 
    </h6>

    <div class="container">

      <div class='col col-12'>
        <img src="/CHAMP/imgs/champ.png" width="50%" style="margin-left: auto; margin-right: auto; margin-top: 1.5em; display: block;"><br>
        <p style="text-align: justify; text-justify: inter-word;">
          <b>TLDR:</b> We present a dataset of challenging high school competition-level math problems, distinctly annotated with concepts and hints relevant and helpful for each problem (left panel of the image above), which allows for fine-grained analyses of model's ability to understand and apply such supplemental information. Additionally, we release a parallel corpus of model-generated solutions for each problem, annotated with the first occurrence of mistake (if present, e.g., arithmetic error or question misunderstanding, right panel of the image above), which allows for further model analyses and evaluations of model verification capability.
        </p>
        <p style="text-align: justify; text-justify: inter-word;">
          <b>Try It Yourself:</b> Start with the <a target="_blank" rel="noopener noreferrer" href="/CHAMP/explorer.html">dataset explorer</a>, and follow the <a target="_blank" rel="noopener noreferrer" href="/CHAMP/quickstart.html">quickstart guide</a> to use the dataset in your own benchmarking.
        </p>
        <p style="text-align: justify; text-justify: inter-word;">
          <b>Abstract:</b> Recent large language models (LLMs) have shown indications of mathematical reasoning abilities, but it has not been clear how they would fare on more challenging competition-level problems. Moreover, while self-generated verbalizations of intermediate reasoning steps (i.e.,  chain-of-thought prompting) has been shown to be helpful, whether LLMs can make use of externally-provided concepts and hints that are relevant to the problem at hand has not been investigated before. In this paper, we propose a challenging benchmark dataset for enabling such analyses. The Concept and Hint-Annotated Math Problems, or CHAMP, consists of competition-level math problems at the high school level that are  annotated with <i>concepts</i>, or general math facts, and <i>hints</i>, or problem-specific tricks. These  annotations allow  us to explore the effects of additional information, such as relevant hints, misleading concepts, or related problems. We find that this benchmark is difficult for current LLMs, with the best model only scoring 65.2%. When  models are provided additional concepts and hints, performance sometimes improves, indicating that some models can make use of such additional side information. A manual annotation of model-generated solutions  further reveals that in many cases, models arrive at the seemingly correct solution but through wrong reasoning steps.
        </p>
      </div>

    </div>
  </body>
</html>
